# Day 6: データ型と欠損値処理

## 概要
データ分析と機械学習における基礎要素であるデータ型の理解と、現実のデータに必ず存在する欠損値の適切な処理方法を学習します。データの品質がモデルの性能に直結するため、実践的な前処理技術を身につけます。

## 学習内容

### 基礎編（data_types_missing_values_simple.ipynb）
- **データ型の基礎**
  - Pythonとpandasの主要データ型
  - データ型の確認と変換方法
  - メモリ効率を考慮した型選択

- **欠損値の基本処理**
  - 欠損値の確認と可視化
  - 基本的な削除・補完方法（平均値、中央値、最頻値）
  - 前方補完・後方補完

- **実践的な例**
  - 学生成績データでの欠損値処理
  - ECサイト顧客データでの業務ロジック考慮
  - データ型最適化によるメモリ削減

### ベーシック編（data_types_missing_values_advanced.ipynb）
- **高度な欠損値補完手法**
  - K近傍法（KNN）による補完
  - 回帰による反復補完（Iterative Imputation）
  - 機械学習ベースの補完手法

- **欠損値パターンの分析**
  - MCAR、MAR、MNARの識別
  - 欠損パターンの可視化と統計的検定
  - Little's MCAR testの概念

- **時系列データの欠損値処理**
  - 線形補間・スプライン補間
  - 季節性を考慮した補完
  - 移動平均による補完

- **パフォーマンス最適化**
  - 大規模データでの処理速度比較
  - メモリ効率的なデータ型選択
  - 補完手法の精度評価

- **実践的なケーススタディ**
  - 包括的な前処理パイプライン構築
  - ビジネスロジックに基づく欠損値処理
  - 前処理結果の検証方法

## 主な学習ポイント

### データ型選択の基準
- **整数データ**: 値の範囲に応じてint8, int16, int32を選択
- **浮動小数点**: 精度要件に応じてfloat32, float64を選択
- **カテゴリカルデータ**: category型でメモリとパフォーマンスを改善
- **文字列データ**: 必要に応じてobject型からcategory型への変換

### 欠損値処理の戦略
1. **欠損機構の理解**
   - MCAR (Missing Completely At Random): 完全にランダム
   - MAR (Missing At Random): 他の観測値に依存
   - MNAR (Missing Not At Random): 欠損値自体が値に依存

2. **手法選択の指針**
   - データサイズと欠損率を考慮
   - 計算資源の制約
   - ビジネス要件との整合性
   - 後続分析への影響

3. **補完手法の特徴**
   - **単純補完**: 高速だが情報損失あり
   - **KNN補完**: 相関関係を保持、中程度の計算コスト
   - **回帰補完**: 高精度だが計算コスト高
   - **時系列補間**: 時間的連続性を保持

## 実行環境
- Python 3.x
- 必要なライブラリ：
  - pandas
  - numpy
  - matplotlib
  - japanize-matplotlib（日本語表示用）
  - seaborn
  - scikit-learn
  - scipy（ベーシック編）

### 注意事項
- pandas 2.0以降では、`fillna(method='ffill')`や`fillna(method='bfill')`は非推奨となっています
- 代わりに`ffill()`や`bfill()`メソッドを直接使用してください
  ```python
  # 旧方法（非推奨）
  df.fillna(method='ffill')
  
  # 新方法（推奨）
  df.ffill()
  ```

## 使い方
1. Jupyter Notebookを起動
2. 初心者の方は `data_types_missing_values_simple.ipynb` から始める
3. 基礎ができたら `data_types_missing_values_advanced.ipynb` で高度な手法を学ぶ

## 演習問題
各ノートブックには実践的な演習問題が含まれています：
- 基本的な欠損値処理（平均値・中央値・最頻値補完）
- データ型の最適化
- 補完手法の比較評価
- 実際のビジネスケースでの前処理パイプライン構築

## 実践的なガイドライン

### 欠損値処理のフローチャート
```
データの欠損値を発見
    ↓
欠損率 < 5% ?
    ↓ Yes → 行削除を検討
    ↓ No
計算資源に制約あり?
    ↓ Yes → 単純補完（平均値/中央値/最頻値）
    ↓ No
データに相関関係あり?
    ↓ Yes → KNN補完 or 回帰補完
    ↓ No
時系列データ?
    ↓ Yes → 線形補間 or 季節性考慮補完
    ↓ No
カテゴリカルデータ?
    ↓ Yes → 最頻値 or 新カテゴリ作成
    ↓ No
ビジネスルールの適用
```

### 注意すべきポイント
1. 補完は情報を「創造」するのではなく「推定」する
2. 過度な補完は過学習の原因となる
3. 補完結果は必ず検証・妥当性確認を行う
4. ビジネス要件に反する補完は避ける
5. 補完前のデータも保持し、トレーサビリティを確保

## 次のステップ
- Day 7: 統計基礎①（平均・分散・標準偏差）
- より高度な機械学習ベースの補完手法
- 大規模データでのリアルタイム前処理
- 自動化された前処理パイプラインの構築

## 参考資料
- Pandas公式ドキュメント（データ型とNA処理）
- Scikit-learn補完手法ガイド
- 時系列データの前処理ベストプラクティス